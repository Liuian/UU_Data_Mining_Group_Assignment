### baseline (before any changes)
2025-09-28 16:03:41,015 - INFO - ========== Unigram only ==========
2025-09-28 16:03:46,576 - INFO - Best estimator:Pipeline(steps=[('vect', CountVectorizer(max_features=1000)),('clf', MultinomialNB())])
2025-09-28 16:03:46,577 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 1000}
2025-09-28 16:03:46,577 - INFO - Best score (mean CV F1): 0.8571
2025-09-28 16:03:46,577 - INFO - All grid scores:
2025-09-28 16:03:46,577 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 500} -> mean F1: 0.8342 (std: 0.0319)
2025-09-28 16:03:46,577 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 1000} -> mean F1: 0.8411 (std: 0.0294)
2025-09-28 16:03:46,577 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 2000} -> mean F1: 0.8315 (std: 0.0377)
2025-09-28 16:03:46,577 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 500} -> mean F1: 0.8306 (std: 0.0270)
2025-09-28 16:03:46,578 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 1000} -> mean F1: 0.8536 (std: 0.0277)
2025-09-28 16:03:46,578 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 2000} -> mean F1: 0.8431 (std: 0.0298)
2025-09-28 16:03:46,578 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 500} -> mean F1: 0.8323 (std: 0.0271)
2025-09-28 16:03:46,578 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 1000} -> mean F1: 0.8571 (std: 0.0288)
2025-09-28 16:03:46,578 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 2000} -> mean F1: 0.8374 (std: 0.0247)
2025-09-28 16:03:46,675 - INFO - Test set results (fold 5):
2025-09-28 16:03:46,686 - INFO - 
              precision    recall  f1-score   support

           0     0.8537    0.8750    0.8642        80
           1     0.8718    0.8500    0.8608        80

    accuracy                         0.8625       160
   macro avg     0.8627    0.8625    0.8625       160
weighted avg     0.8627    0.8625    0.8625       160

2025-09-28 16:03:46,688 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'smell']
2025-09-28 16:03:46,688 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-09-28 16:03:46,688 - INFO - ========== Unigram + Bigram ==========
2025-09-28 16:03:50,357 - INFO - Best estimator:Pipeline(steps=[('vect',
                 CountVectorizer(max_features=1000, ngram_range=(1, 2))),
                ('clf', MultinomialNB())])
2025-09-28 16:03:50,357 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 1000}
2025-09-28 16:03:50,358 - INFO - Best score (mean CV F1): 0.8726
2025-09-28 16:03:50,358 - INFO - All grid scores:
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 500} -> mean F1: 0.8387 (std: 0.0309)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 1000} -> mean F1: 0.8640 (std: 0.0339)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 2000} -> mean F1: 0.8514 (std: 0.0415)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 500} -> mean F1: 0.8414 (std: 0.0318)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 1000} -> mean F1: 0.8691 (std: 0.0397)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 2000} -> mean F1: 0.8591 (std: 0.0347)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 500} -> mean F1: 0.8463 (std: 0.0294)
2025-09-28 16:03:50,358 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 1000} -> mean F1: 0.8726 (std: 0.0363)
2025-09-28 16:03:50,359 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 2000} -> mean F1: 0.8651 (std: 0.0347)
2025-09-28 16:03:50,640 - INFO - Test set results (fold 5):
2025-09-28 16:03:50,664 - INFO -               precision    recall  f1-score   support

           0     0.8132    0.9250    0.8655        80
           1     0.9130    0.7875    0.8456        80

    accuracy                         0.8562       160
   macro avg     0.8631    0.8562    0.8556       160
weighted avg     0.8631    0.8562    0.8556       160

2025-09-28 16:03:50,667 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel towers'
 'millennium knickerbocker' 'luxury hotel']
2025-09-28 16:03:50,667 - INFO - Top 5 genuine-indicative words: ['priceline' '25' 'sofa' 'fridge' 'booked hotel']
2025-09-28 16:03:50,668 - INFO - === End this run ===






# preprocess: remove unwanted tokens. example: 's, n't, etc.

2025-10-01 19:29:44,396 - INFO - ========== Unigram only ==========
2025-10-01 19:29:48,864 - INFO - Best estimator:Pipeline(steps=[('vect', CountVectorizer(max_features=1000)),
                ('clf', MultinomialNB())])
2025-10-01 19:29:48,865 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 1000}
2025-10-01 19:29:48,865 - INFO - Best score (mean CV F1): 0.8558
2025-10-01 19:29:48,865 - INFO - All grid scores:
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 500} -> mean F1: 0.8336 (std: 0.0298)
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 1000} -> mean F1: 0.8432 (std: 0.0279)
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 2000} -> mean F1: 0.8363 (std: 0.0385)
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 500} -> mean F1: 0.8324 (std: 0.0293)
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 1000} -> mean F1: 0.8540 (std: 0.0235)
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 2000} -> mean F1: 0.8448 (std: 0.0279)
2025-10-01 19:29:48,866 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 500} -> mean F1: 0.8336 (std: 0.0298)
2025-10-01 19:29:48,867 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 1000} -> mean F1: 0.8558 (std: 0.0223)
2025-10-01 19:29:48,867 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 2000} -> mean F1: 0.8362 (std: 0.0221)
2025-10-01 19:29:48,935 - INFO - Test set results (fold 5):
2025-10-01 19:29:48,943 - INFO -               precision    recall  f1-score   support

           0     0.8537    0.8750    0.8642        80
           1     0.8718    0.8500    0.8608        80

    accuracy                         0.8625       160
   macro avg     0.8627    0.8625    0.8625       160
weighted avg     0.8627    0.8625    0.8625       160

2025-10-01 19:29:48,943 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'smell']
2025-10-01 19:29:48,944 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 19:29:48,944 - INFO - ========== Unigram + Bigram ==========
2025-10-01 19:29:51,656 - INFO - Best estimator:Pipeline(steps=[('vect',
                 CountVectorizer(max_features=1000, ngram_range=(1, 2))),
                ('clf', MultinomialNB())])
2025-10-01 19:29:51,656 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 1000}
2025-10-01 19:29:51,656 - INFO - Best score (mean CV F1): 0.8729
2025-10-01 19:29:51,656 - INFO - All grid scores:
2025-10-01 19:29:51,656 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 500} -> mean F1: 0.8506 (std: 0.0302)
2025-10-01 19:29:51,656 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 1000} -> mean F1: 0.8688 (std: 0.0478)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 0.1, 'vect__max_features': 2000} -> mean F1: 0.8454 (std: 0.0332)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 500} -> mean F1: 0.8501 (std: 0.0308)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 1000} -> mean F1: 0.8712 (std: 0.0451)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 0.5, 'vect__max_features': 2000} -> mean F1: 0.8562 (std: 0.0399)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 500} -> mean F1: 0.8496 (std: 0.0312)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 1000} -> mean F1: 0.8729 (std: 0.0432)
2025-10-01 19:29:51,657 - INFO -   {'clf__alpha': 1.0, 'vect__max_features': 2000} -> mean F1: 0.8604 (std: 0.0356)
2025-10-01 19:29:51,860 - INFO - Test set results (fold 5):
2025-10-01 19:29:51,867 - INFO -               precision    recall  f1-score   support

           0     0.8182    0.9000    0.8571        80
           1     0.8889    0.8000    0.8421        80

    accuracy                         0.8500       160
   macro avg     0.8535    0.8500    0.8496       160
weighted avg     0.8535    0.8500    0.8496       160

2025-10-01 19:29:51,868 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel towers' 'luxury hotel'
 'millennium knickerbocker']
2025-10-01 19:29:51,868 - INFO - Top 5 genuine-indicative words: ['priceline' '25' 'sofa' 'booked hotel' 'fridge']
2025-10-01 19:29:51,869 - INFO - === End this run ===






### preprocess: lemmatization
2025-10-01 21:23:40,058 - INFO - ========== Unigram only ==========
2025-10-01 21:23:48,045 - INFO - Best estimator:Pipeline(steps=[('vect', CountVectorizer(max_features=2000)),
                ('clf', MultinomialNB(alpha=0.5))])
2025-10-01 21:23:48,046 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 2000}
2025-10-01 21:23:48,046 - INFO - Best score (mean CV F1): 0.8515
2025-10-01 21:23:48,117 - INFO - Test set results (fold 5):
2025-10-01 21:23:48,126 - INFO -               precision    recall  f1-score   support

           0     0.8846    0.8625    0.8734        80
           1     0.8659    0.8875    0.8765        80

    accuracy                         0.8750       160
   macro avg     0.8752    0.8750    0.8750       160
weighted avg     0.8752    0.8750    0.8750       160

2025-10-01 21:23:48,127 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'settled' 'egg' 'luxury']
2025-10-01 21:23:48,128 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 21:23:48,128 - INFO - ========== Unigram + Bigram ==========
2025-10-01 21:23:51,386 - INFO - Best estimator:Pipeline(steps=[('vect',
                 CountVectorizer(max_features=2000, ngram_range=(1, 2))),
                ('clf', MultinomialNB())])
2025-10-01 21:23:51,386 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 2000}
2025-10-01 21:23:51,386 - INFO - Best score (mean CV F1): 0.8677
2025-10-01 21:23:51,603 - INFO - Test set results (fold 5):
2025-10-01 21:23:51,611 - INFO -               precision    recall  f1-score   support

           0     0.8523    0.9375    0.8929        80
           1     0.9306    0.8375    0.8816        80

    accuracy                         0.8875       160
   macro avg     0.8914    0.8875    0.8872       160
weighted avg     0.8914    0.8875    0.8872       160

2025-10-01 21:23:51,612 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-01 21:23:51,613 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'booked hotel']
2025-10-01 21:23:51,613 - INFO - === End this run ===






### Expand the hyperparameter grid for alpha and max_features.
2025-10-01 21:34:06,278 - INFO - ========== Unigram only ==========
2025-10-01 21:34:14,433 - INFO - Best estimator:Pipeline(steps=[('vect', CountVectorizer(max_features=3000)),
                ('clf', MultinomialNB())])
2025-10-01 21:34:14,434 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-01 21:34:14,434 - INFO - Best score (mean CV F1): 0.8601
2025-10-01 21:34:14,499 - INFO - Test set results (fold 5):
2025-10-01 21:34:14,508 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-01 21:34:14,511 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-01 21:34:14,511 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 21:34:14,512 - INFO - ========== Unigram + Bigram ==========
2025-10-01 21:34:19,167 - INFO - Best estimator:Pipeline(steps=[('vect',
                 CountVectorizer(max_features=3000, ngram_range=(1, 2))),
                ('clf', MultinomialNB(alpha=0.5))])
2025-10-01 21:34:19,167 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 3000}
2025-10-01 21:34:19,167 - INFO - Best score (mean CV F1): 0.8724
2025-10-01 21:34:19,408 - INFO - Test set results (fold 5):
2025-10-01 21:34:19,417 - INFO -               precision    recall  f1-score   support

           0     0.8427    0.9375    0.8876        80
           1     0.9296    0.8250    0.8742        80

    accuracy                         0.8812       160
   macro avg     0.8861    0.8812    0.8809       160
weighted avg     0.8861    0.8812    0.8809       160

2025-10-01 21:34:19,420 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-01 21:34:19,420 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-01 21:34:19,421 - INFO - === End this run ===





### replace CountVectorizer with TfidfVectorizer
2025-10-01 22:21:56,666 - INFO - ========== Unigram only ==========
2025-10-01 22:22:08,604 - INFO - Best estimator:Pipeline(steps=[('vect', TfidfVectorizer(max_features=1000)),
                ('clf', MultinomialNB(alpha=0.5))])
2025-10-01 22:22:08,604 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 1000}
2025-10-01 22:22:08,604 - INFO - Best score (mean CV F1): 0.8515
2025-10-01 22:22:08,722 - INFO - Test set results (fold 5):
2025-10-01 22:22:08,734 - INFO -               precision    recall  f1-score   support

           0     0.8642    0.8750    0.8696        80
           1     0.8734    0.8625    0.8679        80

    accuracy                         0.8688       160
   macro avg     0.8688    0.8688    0.8687       160
weighted avg     0.8688    0.8688    0.8687       160

2025-10-01 22:22:08,735 - INFO - Top 5 fake-indicative words: ['luxury' 'millennium' 'smell' 'relax' 'turned']
2025-10-01 22:22:08,736 - INFO - Top 5 genuine-indicative words: ['priceline' 'elevator' 'cool' '25' 'security']
2025-10-01 22:22:08,737 - INFO - ========== Unigram + Bigram ==========
2025-10-01 22:22:18,350 - INFO - Best estimator:Pipeline(steps=[('vect',
                 TfidfVectorizer(max_features=3500, ngram_range=(1, 2))),
                ('clf', MultinomialNB(alpha=0.1))])
2025-10-01 22:22:18,350 - INFO - Best params: {'clf__alpha': 0.1, 'vect__max_features': 3500}
2025-10-01 22:22:18,351 - INFO - Best score (mean CV F1): 0.8683
2025-10-01 22:22:18,712 - INFO - Test set results (fold 5):
2025-10-01 22:22:18,724 - INFO -               precision    recall  f1-score   support

           0     0.8452    0.8875    0.8659        80
           1     0.8816    0.8375    0.8590        80

    accuracy                         0.8625       160
   macro avg     0.8634    0.8625    0.8624       160
weighted avg     0.8634    0.8625    0.8624       160

2025-10-01 22:22:18,728 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower' 'james chicago'
 'millennium knickerbocker']
2025-10-01 22:22:18,728 - INFO - Top 5 genuine-indicative words: ['priceline' 'booked hotel' '25' 'sofa' 'fridge']
2025-10-01 22:22:18,728 - INFO - === End this run ===






### Try different n_splits
2025-10-01 22:35:39,050 - INFO - ========== Unigram only ==========
2025-10-01 22:35:43,273 - INFO - --- GridSearchCV with StratifiedKFold n_splits=3 ---
2025-10-01 22:35:47,229 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 2000}
2025-10-01 22:35:47,230 - INFO - Best score (mean CV F1): 0.8548
2025-10-01 22:35:47,291 - INFO - Test set results (fold 5):
2025-10-01 22:35:47,300 - INFO -               precision    recall  f1-score   support

           0     0.8846    0.8625    0.8734        80
           1     0.8659    0.8875    0.8765        80

    accuracy                         0.8750       160
   macro avg     0.8752    0.8750    0.8750       160
weighted avg     0.8752    0.8750    0.8750       160

2025-10-01 22:35:47,302 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'settled' 'egg' 'luxury']
2025-10-01 22:35:47,303 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 22:35:47,303 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-01 22:35:49,123 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-01 22:35:49,123 - INFO - Best score (mean CV F1): 0.8601
2025-10-01 22:35:49,197 - INFO - Test set results (fold 5):
2025-10-01 22:35:49,205 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-01 22:35:49,209 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-01 22:35:49,209 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 22:35:49,209 - INFO - --- GridSearchCV with StratifiedKFold n_splits=5 ---
2025-10-01 22:35:51,653 - INFO - Best params: {'clf__alpha': 0.1, 'vect__max_features': 1000}
2025-10-01 22:35:51,654 - INFO - Best score (mean CV F1): 0.8693
2025-10-01 22:35:51,729 - INFO - Test set results (fold 5):
2025-10-01 22:35:51,737 - INFO -               precision    recall  f1-score   support

           0     0.8571    0.9000    0.8780        80
           1     0.8947    0.8500    0.8718        80

    accuracy                         0.8750       160
   macro avg     0.8759    0.8750    0.8749       160
weighted avg     0.8759    0.8750    0.8749       160

2025-10-01 22:35:51,739 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'settled' 'cigarette' 'luxury']
2025-10-01 22:35:51,739 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 22:35:51,739 - INFO - --- GridSearchCV with StratifiedKFold n_splits=8 ---
2025-10-01 22:35:55,754 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-01 22:35:55,767 - INFO - Best score (mean CV F1): 0.8750
2025-10-01 22:35:55,846 - INFO - Test set results (fold 5):
2025-10-01 22:35:55,855 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-01 22:35:55,860 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-01 22:35:55,860 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 22:35:55,860 - INFO - --- GridSearchCV with StratifiedKFold n_splits=10 ---
2025-10-01 22:36:00,846 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-01 22:36:00,846 - INFO - Best score (mean CV F1): 0.8740
2025-10-01 22:36:00,922 - INFO - Test set results (fold 5):
2025-10-01 22:36:00,930 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-01 22:36:00,935 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-01 22:36:00,935 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-01 22:36:00,935 - INFO - ========== Unigram + Bigram ==========
2025-10-01 22:36:02,322 - INFO - --- GridSearchCV with StratifiedKFold n_splits=3 ---
2025-10-01 22:36:06,483 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 2000}
2025-10-01 22:36:06,485 - INFO - Best score (mean CV F1): 0.8736
2025-10-01 22:36:06,707 - INFO - Test set results (fold 5):
2025-10-01 22:36:06,714 - INFO -               precision    recall  f1-score   support

           0     0.8523    0.9375    0.8929        80
           1     0.9306    0.8375    0.8816        80

    accuracy                         0.8875       160
   macro avg     0.8914    0.8875    0.8872       160
weighted avg     0.8914    0.8875    0.8872       160

2025-10-01 22:36:06,715 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-01 22:36:06,716 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'booked hotel']
2025-10-01 22:36:06,716 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-01 22:36:12,584 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 3000}
2025-10-01 22:36:12,584 - INFO - Best score (mean CV F1): 0.8724
2025-10-01 22:36:12,816 - INFO - Test set results (fold 5):
2025-10-01 22:36:12,823 - INFO -               precision    recall  f1-score   support

           0     0.8427    0.9375    0.8876        80
           1     0.9296    0.8250    0.8742        80

    accuracy                         0.8812       160
   macro avg     0.8861    0.8812    0.8809       160
weighted avg     0.8861    0.8812    0.8809       160

2025-10-01 22:36:12,826 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-01 22:36:12,826 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-01 22:36:12,826 - INFO - --- GridSearchCV with StratifiedKFold n_splits=5 ---
2025-10-01 22:36:20,787 - INFO - Best params: {'clf__alpha': 0.1, 'vect__max_features': 1000}
2025-10-01 22:36:20,787 - INFO - Best score (mean CV F1): 0.8806
2025-10-01 22:36:21,019 - INFO - Test set results (fold 5):
2025-10-01 22:36:21,028 - INFO -               precision    recall  f1-score   support

           0     0.7957    0.9250    0.8555        80
           1     0.9104    0.7625    0.8299        80

    accuracy                         0.8438       160
   macro avg     0.8531    0.8438    0.8427       160
weighted avg     0.8531    0.8438    0.8427       160

2025-10-01 22:36:21,031 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'millennium knickerbocker'
 'hotel tower' 'relax']
2025-10-01 22:36:21,031 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-01 22:36:21,031 - INFO - --- GridSearchCV with StratifiedKFold n_splits=8 ---
2025-10-01 22:36:34,098 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 1000}
2025-10-01 22:36:34,099 - INFO - Best score (mean CV F1): 0.8848
2025-10-01 22:36:34,315 - INFO - Test set results (fold 5):
2025-10-01 22:36:34,322 - INFO -               precision    recall  f1-score   support

           0     0.8043    0.9250    0.8605        80
           1     0.9118    0.7750    0.8378        80

    accuracy                         0.8500       160
   macro avg     0.8581    0.8500    0.8492       160
weighted avg     0.8581    0.8500    0.8492       160

2025-10-01 22:36:34,323 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-01 22:36:34,323 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-01 22:36:34,324 - INFO - --- GridSearchCV with StratifiedKFold n_splits=10 ---
2025-10-01 22:36:50,068 - INFO - Best params: {'clf__alpha': 0.1, 'vect__max_features': 1000}
2025-10-01 22:36:50,069 - INFO - Best score (mean CV F1): 0.8857
2025-10-01 22:36:50,334 - INFO - Test set results (fold 5):
2025-10-01 22:36:50,343 - INFO -               precision    recall  f1-score   support

           0     0.7957    0.9250    0.8555        80
           1     0.9104    0.7625    0.8299        80

    accuracy                         0.8438       160
   macro avg     0.8531    0.8438    0.8427       160
weighted avg     0.8531    0.8438    0.8427       160

2025-10-01 22:36:50,344 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'millennium knickerbocker'
 'hotel tower' 'relax']
2025-10-01 22:36:50,345 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-01 22:36:50,345 - INFO - === End this run ===






2025-10-13 20:40:59,633 - INFO - ========== Unigram only (CountVectorizer) ==========
2025-10-13 20:41:04,412 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-13 20:41:04,413 - INFO - Using CountVectorizer
2025-10-13 20:41:14,527 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-13 20:41:14,544 - INFO - Best score (mean CV F1): 0.8601
2025-10-13 20:41:14,640 - INFO - Test set results (fold 5):
2025-10-13 20:41:14,657 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-13 20:41:14,662 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-13 20:41:14,662 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-13 20:41:14,665 - INFO - ========== Unigram + Bigram (CountVectorizer) ==========
2025-10-13 20:41:16,300 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-13 20:41:16,301 - INFO - Using CountVectorizer
2025-10-13 20:41:21,696 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 3000}
2025-10-13 20:41:21,697 - INFO - Best score (mean CV F1): 0.8724
2025-10-13 20:41:21,944 - INFO - Test set results (fold 5):
2025-10-13 20:41:21,954 - INFO -               precision    recall  f1-score   support

           0     0.8427    0.9375    0.8876        80
           1     0.9296    0.8250    0.8742        80

    accuracy                         0.8812       160
   macro avg     0.8861    0.8812    0.8809       160
weighted avg     0.8861    0.8812    0.8809       160

2025-10-13 20:41:21,957 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-13 20:41:21,958 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-13 20:41:21,959 - INFO - ========== Unigram only (TfidfVectorizer) ==========
2025-10-13 20:41:23,336 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-13 20:41:23,337 - INFO - Using TfidfVectorizer
2025-10-13 20:41:25,307 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 1000}
2025-10-13 20:41:25,308 - INFO - Best score (mean CV F1): 0.8515
2025-10-13 20:41:25,377 - INFO - Test set results (fold 5):
2025-10-13 20:41:25,400 - INFO -               precision    recall  f1-score   support

           0     0.8642    0.8750    0.8696        80
           1     0.8734    0.8625    0.8679        80

    accuracy                         0.8688       160
   macro avg     0.8688    0.8688    0.8687       160
weighted avg     0.8688    0.8688    0.8687       160

2025-10-13 20:41:25,402 - INFO - Top 5 fake-indicative words: ['luxury' 'millennium' 'smell' 'relax' 'turned']
2025-10-13 20:41:25,403 - INFO - Top 5 genuine-indicative words: ['priceline' 'elevator' 'cool' '25' 'security']
2025-10-13 20:41:25,404 - INFO - ========== Unigram + Bigram (TfidfVectorizer) ==========
2025-10-13 20:41:26,719 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-13 20:41:26,720 - INFO - Using TfidfVectorizer
2025-10-13 20:41:33,906 - INFO - Best params: {'clf__alpha': 0.1, 'vect__max_features': 3500}
2025-10-13 20:41:33,907 - INFO - Best score (mean CV F1): 0.8683
2025-10-13 20:41:34,189 - INFO - Test set results (fold 5):
2025-10-13 20:41:34,198 - INFO -               precision    recall  f1-score   support

           0     0.8452    0.8875    0.8659        80
           1     0.8816    0.8375    0.8590        80

    accuracy                         0.8625       160
   macro avg     0.8634    0.8625    0.8624       160
weighted avg     0.8634    0.8625    0.8624       160

2025-10-13 20:41:34,202 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower' 'james chicago'
 'millennium knickerbocker']
2025-10-13 20:41:34,203 - INFO - Top 5 genuine-indicative words: ['priceline' 'booked hotel' '25' 'sofa' 'fridge']
2025-10-13 20:41:34,204 - INFO - === End this run ===






2025-10-14 18:02:35,702 - INFO - ========== Unigram only (CountVectorizer) ==========
2025-10-14 18:02:42,435 - INFO - Unigram best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-14 18:02:42,439 - INFO - Unigram best score (mean CV F1): 0.8601
2025-10-14 18:02:42,441 - INFO - ========== Unigram + Bigram (FeatureUnion, GridSearchCV) ==========
2025-10-14 18:02:50,351 - INFO - Combined best params: {'clf__alpha': 1.0, 'features__bigram__max_features': 1000}
2025-10-14 18:02:50,353 - INFO - Combined best score (mean CV F1): 0.8752
2025-10-14 18:02:50,390 - INFO - Test set results (fold 5):
2025-10-14 18:02:50,399 - INFO -               precision    recall  f1-score   support

           0     0.8488    0.9125    0.8795        80
           1     0.9054    0.8375    0.8701        80

    accuracy                         0.8750       160
   macro avg     0.8771    0.8750    0.8748       160
weighted avg     0.8771    0.8750    0.8748       160

2025-10-14 18:02:50,403 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'millennium knickerbocker'
 'hotel tower' 'relax']
2025-10-14 18:02:50,404 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'booked hotel']
2025-10-14 18:02:50,406 - INFO - === End this run ===






2025-10-14 18:04:58,673 - INFO - ========== Unigram only (CountVectorizer) ==========
2025-10-14 18:05:05,227 - INFO - Unigram best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-14 18:05:05,232 - INFO - Unigram best score (mean CV F1): 0.8601
2025-10-14 18:05:05,316 - INFO - Unigram Test set results (fold 5):
2025-10-14 18:05:05,328 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-14 18:05:05,332 - INFO - Unigram Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-14 18:05:05,336 - INFO - Unigram Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']
2025-10-14 18:05:05,337 - INFO - ========== Unigram + Bigram (FeatureUnion, GridSearchCV) ==========
2025-10-14 18:05:12,185 - INFO - Combined best params: {'clf__alpha': 1.0, 'features__bigram__max_features': 1000}
2025-10-14 18:05:12,186 - INFO - Combined best score (mean CV F1): 0.8752
2025-10-14 18:05:12,219 - INFO - Test set results (fold 5):
2025-10-14 18:05:12,227 - INFO -               precision    recall  f1-score   support

           0     0.8488    0.9125    0.8795        80
           1     0.9054    0.8375    0.8701        80

    accuracy                         0.8750       160
   macro avg     0.8771    0.8750    0.8748       160
weighted avg     0.8771    0.8750    0.8748       160

2025-10-14 18:05:12,231 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'millennium knickerbocker'
 'hotel tower' 'relax']
2025-10-14 18:05:12,233 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'booked hotel']
2025-10-14 18:05:12,236 - INFO - === End this run ===













2025-10-15 13:51:10,794 - INFO - ========== Unigram only ==========
2025-10-15 13:51:15,057 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-15 13:51:20,700 - INFO - Best params: {'clf__alpha': 1.0, 'vect__max_features': 3000}
2025-10-15 13:51:20,700 - INFO - Best score (mean CV F1): 0.8601
2025-10-15 13:51:20,767 - INFO - Test set results (fold 5):
2025-10-15 13:51:20,777 - INFO -               precision    recall  f1-score   support

           0     0.8875    0.8875    0.8875        80
           1     0.8875    0.8875    0.8875        80

    accuracy                         0.8875       160
   macro avg     0.8875    0.8875    0.8875       160
weighted avg     0.8875    0.8875    0.8875       160

2025-10-15 13:51:20,779 - INFO - Top 5 fake-indicative words: ['relax' 'originally' 'luxury' 'settled' 'egg']
2025-10-15 13:51:20,779 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'fridge' 'stated']

2025-10-15 13:51:20,780 - INFO - ========== Unigram + Bigram ==========
2025-10-15 13:51:22,792 - INFO - --- GridSearchCV with StratifiedKFold n_splits=4 ---
2025-10-15 13:51:28,744 - INFO - Best params: {'clf__alpha': 0.5, 'vect__max_features': 3000}
2025-10-15 13:51:28,744 - INFO - Best score (mean CV F1): 0.8724
2025-10-15 13:51:29,063 - INFO - Test set results (fold 5):
2025-10-15 13:51:29,076 - INFO -               precision    recall  f1-score   support

           0     0.8427    0.9375    0.8876        80
           1     0.9296    0.8250    0.8742        80

    accuracy                         0.8812       160
   macro avg     0.8861    0.8812    0.8809       160
weighted avg     0.8861    0.8812    0.8809       160

2025-10-15 13:51:29,078 - INFO - Top 5 fake-indicative words: ['chicago millennium' 'sheraton chicago' 'hotel tower'
 'millennium knickerbocker' 'relax']
2025-10-15 13:51:29,079 - INFO - Top 5 genuine-indicative words: ['priceline' 'sofa' '25' 'booked hotel' 'fridge']
2025-10-15 13:51:29,081 - INFO - === End this run ===






